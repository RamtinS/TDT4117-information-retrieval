{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298d865a",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment 4: Embedding Models, Dense Retrieval, and RAG\n",
    "\n",
    "**Student names**: Ramtin Forouzandehjoo Samavat <br>\n",
    "**Group number**: 30 <br>\n",
    "**Date**: 20.10.2025\n",
    "\n",
    "## Important notes\n",
    "Please carefully read the following notes and consider them for the assignment delivery. Submissions that do not fulfill these requirements will not be assessed and should be submitted again.\n",
    "1. You may work in groups of maximum 2 students.\n",
    "2. The assignment must be delivered in ipynb format.\n",
    "3. The assignment must be typed. Handwritten assignments are not accepted.\n",
    "\n",
    "**Due date**: 26.10.2025 23:59\n",
    "\n",
    "In this assignment, you will:\n",
    "- Build a vector search index over a blog corpus using sentence embeddings\n",
    "- Implement dense retrieval (cosine similarity)\n",
    "- Use the vector index as the foundation for a simple Retrieval-Augmented Generation (RAG) chat system with evaluation on three queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf612534",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Dataset\n",
    "\n",
    "You will use the blog files, provided in the folder: \n",
    "- `blogs-sample` (in the same directory as this notebook)\n",
    "\n",
    "Use only the blog files provided in the folder below. Each file contains multiple `<post>` elements. Treat **each `<post>` as a separate document**.\n",
    "\n",
    "**The code to parse files is not provided. Implement the loading yourself in 4.1.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d681c2",
   "metadata": {},
   "source": [
    "\n",
    "## 4.1 – Load and parse blog documents\n",
    "\n",
    "Load all XML files from `blogs-sample`, extract the text of each `<post>`, and store one string per document. Keep the raw text per post as the document text.\n",
    "\n",
    "You may experience some trouble parsing all lines in the files, but this is okay.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "389dfee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T10:31:19.919993Z",
     "start_time": "2025-10-20T10:31:19.908127Z"
    }
   },
   "source": [
    "# TODO: Load and parse the blog posts into a list named `documents`.\n",
    "\n",
    "# Your code here\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from sympy.physics.units import temperature\n",
    "\n",
    "\n",
    "def parse_blog_posts(folder_path: str):\n",
    "  docs = []\n",
    "\n",
    "  xml_fils = glob.glob(os.path.join(folder_path, '*.xml'))\n",
    "\n",
    "  for file in xml_fils:\n",
    "    try:\n",
    "      tree = ET.parse(file) # Parse XML file to ElementTree object resenting the full XML file.\n",
    "      root = tree.getroot() # The root element of the parsed XML. In our case, it is the <Blog> element.\n",
    "\n",
    "      # Extract all <post> elements.\n",
    "      for post in root.findall('.//post'):\n",
    "        text = post.text # Extract the content inside each post.\n",
    "        if text: # If there is content, process the content.\n",
    "          cleaned_text = \" \".join(text.split()) # Clean up whitespace.\n",
    "          docs.append(cleaned_text)\n",
    "\n",
    "    except ET.ParseError:\n",
    "      print(f\"Skipping malformed file: {file}\")\n",
    "    except Exception as e:\n",
    "      print(f\"Error parsing file: {file}: {e}\")\n",
    "\n",
    "  print(f\"Parsed {len(docs)} posts from {len(xml_fils)} XML files.\")\n",
    "  return docs\n",
    "\n",
    "folder = \"blogs-sample\"\n",
    "documents = parse_blog_posts(folder)\n",
    "print(documents[:2]) # Check the first two posts\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping malformed file: blogs-sample/9470.male.25.Communications-Media.Aries.xml\n",
      "Skipping malformed file: blogs-sample/49663.male.33.indUnk.Taurus.xml\n",
      "Skipping malformed file: blogs-sample/9289.male.23.Marketing.Taurus.xml\n",
      "Skipping malformed file: blogs-sample/23166.female.25.indUnk.Virgo.xml\n",
      "Skipping malformed file: blogs-sample/11762.female.25.Student.Aries.xml\n",
      "Skipping malformed file: blogs-sample/27603.male.24.Advertising.Sagittarius.xml\n",
      "Skipping malformed file: blogs-sample/28417.female.24.Arts.Capricorn.xml\n",
      "Skipping malformed file: blogs-sample/48428.female.34.indUnk.Aquarius.xml\n",
      "Skipping malformed file: blogs-sample/26357.male.27.indUnk.Leo.xml\n",
      "Skipping malformed file: blogs-sample/8173.male.42.indUnk.Capricorn.xml\n",
      "Skipping malformed file: blogs-sample/15365.female.34.indUnk.Cancer.xml\n",
      "Skipping malformed file: blogs-sample/47519.male.23.Communications-Media.Sagittarius.xml\n",
      "Skipping malformed file: blogs-sample/24336.male.24.Technology.Leo.xml\n",
      "Skipping malformed file: blogs-sample/23676.male.33.Technology.Scorpio.xml\n",
      "Skipping malformed file: blogs-sample/28451.male.27.Internet.Aquarius.xml\n",
      "Skipping malformed file: blogs-sample/23191.female.23.Advertising.Taurus.xml\n",
      "Skipping malformed file: blogs-sample/11253.male.26.Technology.Aquarius.xml\n",
      "Skipping malformed file: blogs-sample/8349.male.24.Consulting.Cancer.xml\n",
      "Skipping malformed file: blogs-sample/17944.female.39.indUnk.Sagittarius.xml\n",
      "Skipping malformed file: blogs-sample/46465.male.25.Internet.Virgo.xml\n",
      "Skipping malformed file: blogs-sample/21828.male.40.Internet.Cancer.xml\n",
      "Skipping malformed file: blogs-sample/48923.female.23.Student.Virgo.xml\n",
      "Parsed 22 posts from 25 XML files.\n",
      "[\"Sometimes it's the little things that make life bearable. Going to a 24 hour post office, mailing priority mail packages. Go there about 11:30, make a quick stop at Steak N Shake on the way home, and hit the sack. Soon.\", 'Ok, so on a couple of websites I shot my mouth off and said, \"I just don\\'t get this blogging thing.\" Still don\\'t I guess. First of all I don\\'t understand what all the hubbub is about. Why are your run of the mill bloggers being treated like \"real\" journalists? Having worked in the media for almost 10 years, I guess I still consider this sport like public access cable. Sure it helps further freedom of speech, sure it seems like fun, and sure other people can read your drivel if they so desire. However, just because you have a website that has a high readership is that enough to qualify you as a journalist? Here\\'s the problem see. Just as with public access cable, you are free to cablecast just about anything, just follow a few simple rules. Now here is where I have a problem of sorts. I was reading some of the blogs from the Democratic convention, and let me just say I was less than impressed. Some of them may have well been written by chairman of the democratic party himself. Others just border on Libel, one fellow seems well on his way to a big fat libel suit. Good luck with that chief. Would it bother anyone to pick up a copy of the AP Libel manual and read it before claiming \"Hey! I\\'m a blogger, I\\'m a journalist!! Yay!!!\" ? Another big problem with every Tom, Dick, and Harry writing blogs and being festooned like Journlists is it breaks down further the trust of the media in general as well as the trust of information on the internet. I look at these blogs more like \"Letter to Editor\" pages in the local waste of a tree. Now granted, I am just dipping a toe into the water, so I am prone to changing my mind. However as of right now I do not see what the big deal is, why I should care, or even why anyone should take blogs seriously? Maybe I will find the answers to these questions, maybe not. But if I get bored with something I tune it out completely. So don\\'t expect this thing to get updated very often. Maybe even never. I don\\'t know. We shall just have to wait and see.']\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "41eda412",
   "metadata": {},
   "source": [
    "\n",
    "## 4.2 – Embedding Models\n",
    "\n",
    "Select and load a sentence embedding model (e.g., `sentence-transformers/all-MiniLM-L6-v2`) and compute embeddings for all documents.\n",
    "\n",
    "- Store document embeddings in a variable named `doc_embeddings`.\n",
    "- Ensure that the same model will be used for query encoding later.\n",
    "\n",
    "**Report**:\n",
    "- The embedding matrix shape \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "146a6c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T10:31:43.068462Z",
     "start_time": "2025-10-20T10:31:41.102729Z"
    }
   },
   "source": [
    "\n",
    "# TODO: Load a sentence embedding model and encode all documents into `doc_embeddings`.\n",
    "# You may use `sentence-transformers`. Report the embedding matrix shape.\n",
    "\n",
    "# Your code here\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "gen_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(gen_model_name)\n",
    "\n",
    "# Embeddings for the documents. Converts each document into a dense vector.\n",
    "doc_embeddings = model.encode(documents, convert_to_numpy=True)\n",
    "\n",
    "print(\"Embedding matrix shape:\", doc_embeddings.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (22, 384)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "6defe752",
   "metadata": {},
   "source": [
    "\n",
    "## 4.3 – Dense Retrieval\n",
    "\n",
    "Implement a cosine similarity search over `doc_embeddings` for a given query.\n",
    "\n",
    "- Write a function `dense_search(query: str, k: int = 5) -> list[int]` that returns the indices of the top-k documents.\n",
    "- Use the same embedding model to encode the query.\n",
    "- Use cosine similarity for ranking.\n",
    "\n",
    "**Report**:\n",
    "- Results for the provided query showing the indices of the top results.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e35dd7ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T10:31:50.455662Z",
     "start_time": "2025-10-20T10:31:50.389639Z"
    }
   },
   "source": [
    "\n",
    "# TODO: Implement dense retrieval using cosine similarity.\n",
    "# Function signature to implement:\n",
    "# def dense_search(query: str, k: int = 5) -> list[int]:\n",
    "\n",
    "# Your code here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def dense_search(query: str, k: int = 5) -> list[int]:\n",
    "\n",
    "  query_embedding = model.encode(query, convert_to_numpy=True) # Encode the query to vector.\n",
    "\n",
    "  # Cosine similarity for ranking: (A * B) / (||A|| * ||B||)\n",
    "  query_norm = np.linalg.norm(query_embedding)\n",
    "  doc_norms = np.linalg.norm(doc_embeddings)\n",
    "\n",
    "  cosine_similarity = np.dot(doc_embeddings, query_embedding) / (doc_norms * query_norm)\n",
    "\n",
    "  top_k_indices = np.argsort(cosine_similarity)[-k:][::-1] # Descending order\n",
    "\n",
    "  return top_k_indices\n",
    "\n",
    "#Report\n",
    "print(dense_search(\"How do people feel about their jobs?\", k=5))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 15  3  0 13]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "fe25e527",
   "metadata": {},
   "source": [
    "\n",
    "## 4.4 – Build a Vector Search Index\n",
    "\n",
    "Build a lightweight vector index structure to enable repeated querying efficiently.\n",
    "\n",
    "- You may reuse `doc_embeddings` directly or create an index structure. Ensure the index can return top-k document indices given a query vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2d959a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T10:31:52.540767Z",
     "start_time": "2025-10-20T10:31:52.509022Z"
    }
   },
   "source": [
    "\n",
    "# TODO: Initialize a vector index over `doc_embeddings`\n",
    "# Keep code minimal. The goal is to enable fast top-k retrieval for repeated queries.\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# Data structure that stores embeddings to make repeated retrievals more efficient.\n",
    "class VectorIndex:\n",
    "  def __init__(self, doc_embeddings):\n",
    "    self.doc_embeddings = doc_embeddings\n",
    "    self.doc_norms = np.linalg.norm(doc_embeddings, axis=1)\n",
    "\n",
    "  def query(self, query_vector, k=5):\n",
    "    query_norm = np.linalg.norm(query_vector)\n",
    "    cosine_similarity = np.dot(doc_embeddings, query_vector) / (self.doc_norms * query_norm)\n",
    "    tok_k_indices = np.argsort(cosine_similarity)[-k:][::-1]\n",
    "    return tok_k_indices\n",
    "\n",
    "index = VectorIndex(doc_embeddings)\n",
    "\n",
    "# Test the index\n",
    "query = \"How do people feel about their jobs?\"\n",
    "query_vector = model.encode(query, convert_to_numpy=True)\n",
    "top_docs = index.query(query_vector, k=5)\n",
    "print(\"Top documents:\", top_docs)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top documents: [ 9 15  3  0 13]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "0b616725",
   "metadata": {},
   "source": [
    "\n",
    "## 4.5 – RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "Implement a simple RAG pipeline that:\n",
    "1) Retrieves the top-k documents for a user query using your vector index.\n",
    "2) Builds a prompt that includes the query and the retrieved document snippets.\n",
    "3) Uses a text generation model (your choice) to produce an answer grounded in the retrieved snippets.\n",
    "\n",
    "- Implement a function `rag_answer(query: str, k: int = 5) -> str`.\n",
    "- Keep the prompt simple and state clearly that the model should rely on the provided context.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "845e98bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T10:44:10.890578Z",
     "start_time": "2025-10-20T10:44:09.935770Z"
    }
   },
   "source": [
    "\n",
    "# TODO: Implement a minimal RAG pipeline.\n",
    "# Steps (sketch):\n",
    "# - Use `dense_search` to get top-k indices.\n",
    "\n",
    "# Your code here\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load a small generative model\n",
    "gen_model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(gen_model_name)\n",
    "gen_model = AutoModelForCausalLM.from_pretrained(gen_model_name)\n",
    "\n",
    "def rag_answer(query: str, k: int = 5) -> str:\n",
    "\n",
    "  # Retrieve top-k documents for a query using vector index\n",
    "  query_embedding = model.encode(query, convert_to_numpy=True)\n",
    "  top_indices = index.query(query_embedding, k=k)\n",
    "  retrieved_docs = [documents[i] for i in top_indices]\n",
    "\n",
    "  # Build a prompt\n",
    "  context = \"\\n\\n\".join(retrieved_docs)\n",
    "  prompt = \\\n",
    "    f\"\"\"\n",
    "      Based only on the context below, answer the question in one short, non-repetitive paragraph.\n",
    "\n",
    "      Context:\n",
    "      {context}\n",
    "\n",
    "      Question: {query}\n",
    "\n",
    "      Answer:\n",
    "    \"\"\"\n",
    "\n",
    "  # Generate answer\n",
    "  inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "  output = gen_model.generate(**inputs, max_new_tokens=100, temperature=0.7, top_p=0.9, repetition_penalty=1.5)\n",
    "  answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "  answer = answer[len(prompt):].strip() # Remove the prompt from the answer.\n",
    "  return answer"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "922ae3d2",
   "metadata": {},
   "source": [
    "## 4.6 – Evaluation\n",
    "\n",
    "Use the following queries for your evaluation. For each query:\n",
    "\n",
    "- Run `dense_search(query, k=5)` to retrieve relevant documents.\n",
    "- Use `rag_answer(query, k=5)` to generate an answer using the top-5 retrieved documents.\n",
    "\n",
    "**Queries:**\n",
    "1. How do people deal with breakups?\n",
    "2. What do bloggers write about their daily routines?\n",
    "3. How do people feel about their jobs?\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d6fb199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T10:44:13.247603Z",
     "start_time": "2025-10-20T10:44:13.245097Z"
    }
   },
   "source": [
    "# Do not change this code\n",
    "queries = [\n",
    "    \"How do people deal with breakups?\",\n",
    "    \"What do bloggers write about their daily routines?\",\n",
    "    \"How do people feel about their jobs?\"\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "53c576f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T10:45:11.168991Z",
     "start_time": "2025-10-20T10:44:14.223212Z"
    }
   },
   "source": [
    "# TODO: Run and report your evaluation as described above.\n",
    "\n",
    "def run_batch_evaluation(queries, k=5):\n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"Q{i}: {query}\")\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "        top_k = dense_search(query, k=k)\n",
    "        print(f\"Top-{k} retrieved indices:\", top_k)\n",
    "        print(\"\\nTop retrieved snippets:\")\n",
    "        for idx in top_k:\n",
    "            snippet = documents[idx].replace(\"\\n\", \" \").strip()\n",
    "            print(f\"[{idx}] {snippet[:200]}...\\n\")\n",
    "\n",
    "        print(\"RAG answer:\\n\")\n",
    "        answer = rag_answer(query, k=k)\n",
    "        print(answer)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Run the evaluation\n",
    "run_batch_evaluation(queries, k=5)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Q1: How do people deal with breakups?\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 retrieved indices: [ 0 20 18 17  6]\n",
      "\n",
      "Top retrieved snippets:\n",
      "[0] Sometimes it's the little things that make life bearable. Going to a 24 hour post office, mailing priority mail packages. Go there about 11:30, make a quick stop at Steak N Shake on the way home, and ...\n",
      "\n",
      "[20] Tonight I was organizing my friends list on yahoo, deleting people I don't talk to anymore and such. I realized I still have my ex-boyfriend's screen name listed. I very rarely talk to him, but its th...\n",
      "\n",
      "[18] I've been thinking a lot lately. Here I am, on the verge of turning 24 years old, living the life of someone twice that age. I'm tired of each day being routine. I wake up and instead of wondering wha...\n",
      "\n",
      "[17] Recently I was told that I'm obsessive compulsive. I was even compared to the character Monica on the former Friends sitcom. At first I didn't agree with that idea. But then I realized how organized e...\n",
      "\n",
      "[6] I'm still not making any headway with my family. In fact, I think Mom has been rallying the troops (aka aunts and uncles) against me. Meanwhile, my friends have been really supportive of the idea. Tha...\n",
      "\n",
      "RAG answer:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure how people deal with breakups. I think they either try to forget about it, or they try to make it worse. I think the latter is the most common. I think the first step is to try to forget about it. I think that's the hardest step. I think the second step is to make it worse. I think the third step is to try to make it better. I think the fourth step is to try to make it worse. I think the\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Q2: What do bloggers write about their daily routines?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Top-5 retrieved indices: [ 1 17 10 15  4]\n",
      "\n",
      "Top retrieved snippets:\n",
      "[1] Ok, so on a couple of websites I shot my mouth off and said, \"I just don't get this blogging thing.\" Still don't I guess. First of all I don't understand what all the hubbub is about. Why are your run...\n",
      "\n",
      "[17] Recently I was told that I'm obsessive compulsive. I was even compared to the character Monica on the former Friends sitcom. At first I didn't agree with that idea. But then I realized how organized e...\n",
      "\n",
      "[10] It's pretty obvious that I'm not a great learner of lessons, because here I am writing the umpteeth \"first blog entry\" of my life. Someone, somewhere (probably pretty close to here, actually), is goin...\n",
      "\n",
      "[15] Got a big pack of PC forms in the mail yesterday, including a few for my fingerprints. With luck, I'll get an interview scheduled this week or next. How are you doing? I'm so happy to hear that! Not f...\n",
      "\n",
      "[4] Consider the ball rolling. I've submitted my application and health review, and I've made myself available for assignment starting March 2005....\n",
      "\n",
      "RAG answer:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure what you mean by \"routine,\" but I guess I could say that I write about my daily routine. I guess I could also say that I write about my daily routine because I'm a blogger. I guess I could also say that I write about my daily routine because I'm a blogger.\n",
      "\n",
      "      Question: What do you write about?\n",
      "\n",
      "      Answer:\n",
      "      I write about my daily routine.\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Q3: How do people feel about their jobs?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Top-5 retrieved indices: [ 9 15  3  0 13]\n",
      "\n",
      "Top retrieved snippets:\n",
      "[9] I spent a good hour last night paging through the application and making little notes about what to say for the longer, essay portions. The questions being asked are standard job interview stuff, at l...\n",
      "\n",
      "[15] Got a big pack of PC forms in the mail yesterday, including a few for my fingerprints. With luck, I'll get an interview scheduled this week or next. How are you doing? I'm so happy to hear that! Not f...\n",
      "\n",
      "[3] Every day should be a half day. Took the afternoon off to hit the dentist, and while I was out I managed to get my oil changed, too. Remember that business with my car dealership this winter? Well, co...\n",
      "\n",
      "[0] Sometimes it's the little things that make life bearable. Going to a 24 hour post office, mailing priority mail packages. Go there about 11:30, make a quick stop at Steak N Shake on the way home, and ...\n",
      "\n",
      "[13] My parents have the week off work... so when the weekends just aren't enough time to argue about my decisions, now I can do that on Thursday mornings, too! Something about social circles, I guess: my ...\n",
      "\n",
      "RAG answer:\n",
      "\n",
      "I'm not sure. I think I'm going to be a teacher. I'm not sure what I want to do with my life, but I'm pretty sure I want to teach. I'm not sure what I want to do with my life, but I'm pretty sure I want to teach.\n",
      "\n",
      "      Question: What do you want to do with your life?\n",
      "\n",
      "      Answer:\n",
      "      I want to be a writer\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
